The authors assembled the **Palm Trees Dataset** by capturing aerial images within a palm tree farm located in the Kharj region of Riyadh, Saudi Arabia, utilizing DJI drones. This effort resulted in the compilation of approximately 10,000 instances of palm trees. Moreover, leveraging the geotagged metadata associated with the aerial images, they applied photogrammetry principles and distance corrections to automate the detection of the geographical locations of the identified palm trees. This geolocation method underwent testing using two different drone models, namely the ***DJI Phantom 4 Pro dron*** and ***DJI Mavic Pro dron***. The evaluation revealed an average geolocation accuracy of 2.8 meters.

## Motivation

Counting trees from aerial images poses a significant challenge, with diverse applications spanning forest inventory, crop estimation, and farm management. However, quantifying the number of palm trees in extensive farms presents a particularly formidable task for agricultural authorities, given the sheer volume of trees and the limitations of manual counting methods. The complexity intensifies when the task extends to identifying the GPS locations of palm trees for regulatory purposes. The inadequacy of conventional approaches results in inconsistent data collection regarding palm tree numbers, as highlighted by agricultural experts. To address this issue, the authors introduce a deep learning framework designed to create an inventory of individual palm trees. This framework automates the process of counting and geolocating palm trees using aerial color images captured by unmanned aerial vehicles (UAVs).

## Dataset description

Detecting palm infestation is crucial for accurate crop estimation. However, reliable tree counting methods are equally essential due to the inaccuracies and inefficiencies inherent in traditional counting techniques. To address this challenge, the authors propose an automated tree counting approach from aerial images, which also holds promise for applications such as forest inventory and farm management. To develop this technique, they gathered a dataset comprising 217 UAV images captured in a palm tree farm located in the Kharj region of Saudi Arabia. This dataset encompassed a total of 9,873 instances, including 8,652 palm trees and 1,221 other trees. The authors meticulously annotated this dataset using [Labelme](https://humansignal.com/). Subsequently, they trained a Faster RCNN model—a state-of-the-art two-stage object detection algorithm—on 80% of the dataset (174 images). On the testing dataset comprising 43 images, the model achieved a precision of 94% and a recall of 84% for detecting palm trees. Additionally, the average precision (AP) at an IoU (Intersection over Union) threshold of 0.5 reached 83%.

<img src="https://github.com/dataset-ninja/palm-trees/assets/120389559/57e7f00b-303d-4cac-a438-f4bc9dee3f58" alt="image" width="800">

<span style="font-size: smaller; font-style: italic;">Sample image of the palm counting and geolocation application.</span>

Moreover, the authors have devised an algorithm designed to assign each identified tree with its precise GPS location. This algorithm leverages photogrammetry principles applied to the metadata extracted from drone imagery, including factors such as the drone's altitude and GPS coordinates, image dimensions, calibrated focal length, and yaw angle. Subsequently, a distance correction is implemented based on the ratio between the drone's altitude and the estimated average height of palm trees. This geolocation method underwent rigorous testing using two different drone models, namely the DJI Mavic Pro and Phantom 4 Pro. The assessment revealed that it yielded an average geolocation accuracy of 2.8 meters, with a maximum deviation of 4.9 meters and a standard deviation of 1.2 meters. The GPS tagging allows to uniquely identify, track and count the number of palm trees from a series of drone images, while correctly dealing with the issue of image overlapping while the drone is flying. This procedure can be generalized to the gelocation of any other objects in UAV images.
